{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10062175,"sourceType":"datasetVersion","datasetId":6196574},{"sourceId":1192,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":1028,"modelId":134},{"sourceId":1206,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":1036,"modelId":134},{"sourceId":1186,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":1025,"modelId":134}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom glob import glob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T00:43:22.217879Z","iopub.execute_input":"2024-12-01T00:43:22.218591Z","iopub.status.idle":"2024-12-01T00:43:22.222673Z","shell.execute_reply.started":"2024-12-01T00:43:22.218552Z","shell.execute_reply":"2024-12-01T00:43:22.221771Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Check the number of GPUs available for acceleration\nprint(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T00:43:23.263591Z","iopub.execute_input":"2024-12-01T00:43:23.264441Z","iopub.status.idle":"2024-12-01T00:43:23.269141Z","shell.execute_reply.started":"2024-12-01T00:43:23.264401Z","shell.execute_reply":"2024-12-01T00:43:23.268174Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available: 2\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"model = tf.saved_model.load('/kaggle/input/movenet/tensorflow2/singlepose-thunder/4')\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T00:43:24.724097Z","iopub.execute_input":"2024-12-01T00:43:24.724438Z","iopub.status.idle":"2024-12-01T00:43:35.551485Z","shell.execute_reply.started":"2024-12-01T00:43:24.724408Z","shell.execute_reply":"2024-12-01T00:43:35.550575Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x7da70f71e2c0>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"def extract_keypoints(image_path):\n    \"\"\"\n    Process an image, run inference with MoveNet, and return keypoints.\n    \"\"\"\n    # Load and preprocess the image\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img)\n    img = tf.image.resize(img, (256, 256))  # Resize to model's input size\n    img = tf.cast(img, dtype=tf.int32)  # Ensure datatype matches model requirements\n    img = tf.expand_dims(img, axis=0)  # Add batch dimension\n\n    # Run inference\n    outputs = model.signatures['serving_default'](img)\n    keypoints = outputs['output_0'].numpy()  # [1, 1, 17, 3]\n\n    # Reshape to extract 17 keypoints (x, y, confidence)\n    return keypoints.reshape(17, 3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T00:46:21.419959Z","iopub.execute_input":"2024-12-01T00:46:21.420354Z","iopub.status.idle":"2024-12-01T00:46:21.426330Z","shell.execute_reply.started":"2024-12-01T00:46:21.420320Z","shell.execute_reply":"2024-12-01T00:46:21.425406Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Path to the dataset directory\ndataset_dir = \"/kaggle/input/pose-samples/dataset\"\n\noutput_data = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T00:46:24.298498Z","iopub.execute_input":"2024-12-01T00:46:24.298876Z","iopub.status.idle":"2024-12-01T00:46:24.302983Z","shell.execute_reply.started":"2024-12-01T00:46:24.298845Z","shell.execute_reply":"2024-12-01T00:46:24.302040Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Traverse through each class folder and process images\nfor class_name in os.listdir(dataset_dir):\n    class_path = os.path.join(dataset_dir, class_name)\n    if os.path.isdir(class_path):  # Ensure it's a directory\n        for image_path in glob(f\"{class_path}/*.jpg\"):\n            keypoints = extract_keypoints(image_path)\n            # Flatten keypoints and include class label\n            row = [image_path, class_name] + keypoints.flatten().tolist()\n            output_data.append(row)\n\n# Create DataFrame with columns for file path, class name, and keypoints\ncolumns = [\"filepath\", \"label\"] + [f\"keypoint_{i}_{attr}\" for i in range(1, 18) for attr in [\"x\", \"y\", \"confidence\"]]\ndf = pd.DataFrame(output_data, columns=columns)\n\n# Save to CSV\ndf.to_csv(\"pose_data.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T00:46:26.339547Z","iopub.execute_input":"2024-12-01T00:46:26.339913Z","iopub.status.idle":"2024-12-01T00:51:50.359104Z","shell.execute_reply.started":"2024-12-01T00:46:26.339882Z","shell.execute_reply":"2024-12-01T00:51:50.358010Z"}},"outputs":[],"execution_count":28}]}